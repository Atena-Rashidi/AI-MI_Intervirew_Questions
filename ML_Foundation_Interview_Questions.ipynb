{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ML Foundation Interview Questions & Answers\n",
    "\n",
    "#### 1.1 What is the difference between supervised, unsupervised, and reinforcement learning?\n",
    "\n",
    "**Answer:**\n",
    "- **Supervised Learning:** The model is trained on labeled data, meaning each training example is paired with an output label. The goal is to learn a mapping from inputs to outputs. \n",
    "**Example:** Image classification, where the model learns to classify images into predefined categories.\n",
    "- **Unsupervised Learning:** The model learns patterns from unlabeled data, meaning the data has no output labels. The goal is to find hidden structures in the data. \n",
    "**Example:** Clustering, where the model groups similar data points together.\n",
    "- **Reinforcement Learning (RL):** The model learns by interacting with an environment and receiving rewards or penalties based on its actions. The goal is to learn a policy that maximizes cumulative rewards. \n",
    "**Example:** AlphaGo, where the model learns to play the game of Go by receiving rewards for winning.\n",
    "\n",
    "#### 1.2 What is bias-variance tradeoff?\n",
    "\n",
    "**Answer:**\n",
    "- **Bias:** The error due to overly simplistic models that do not capture the underlying patterns in the data well, leading to underfitting. \n",
    "**Example:** A linear model trying to fit a non-linear relationship.\n",
    "- **Variance:** The error due to overly complex models that capture noise in the training data, leading to overfitting. \n",
    "**Example:** A high-degree polynomial model fitting random noise in the data.\n",
    "- **Tradeoff:** Increasing model complexity reduces bias but increases variance. The goal is to find a balance where both bias and variance are minimized, often achieved through techniques like cross-validation.\n",
    "\n",
    "#### 1.3 Explain precision, recall, F1-score, and accuracy.\n",
    "\n",
    "#### Confusion Matrix Example\n",
    "\n",
    "|                | Predicted Positive | Predicted Negative |\n",
    "|----------------|--------------------|--------------------|\n",
    "| **Actual Positive** | True Positive (TP)      | False Negative (FN)     |\n",
    "| **Actual Negative** | False Positive (FP)     | True Negative (TN)      |\n",
    "\n",
    "**Answer:**\n",
    "- **Accuracy:** The ratio of correctly predicted instances to the total instances. $$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "- **Precision:** The ratio of correctly predicted positive instances to the total predicted positives. $$\\text{Precision} = \\frac{TP}{TP + FP}$$ Measures how many of the predicted positives are actually correct.\n",
    "- **Recall:** The ratio of correctly predicted positive instances to all actual positives. $$\\text{Recall} = \\frac{TP}{TP + FN}$$ Measures how many of the actual positives are correctly identified.\n",
    "- **F1-Score:** The harmonic mean of precision and recall. $$\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$ Used when dealing with imbalanced datasets to balance precision and recall.\n",
    "\n",
    "#### 1.4 How do you handle imbalanced datasets?\n",
    "\n",
    "**Answer:**\n",
    "- **Resampling Techniques:**\n",
    "  - **Oversampling:** Techniques like SMOTE (Synthetic Minority Over-sampling Technique) and ADASYN (Adaptive Synthetic Sampling) create synthetic samples for the minority class.\n",
    "  - **Undersampling:** Techniques like random undersampling and Tomek links reduce the number of samples in the majority class.\n",
    "- **Algorithmic Approaches:**\n",
    "  - **Weighted Loss Functions:** Assign higher weights to the minority class during training.\n",
    "  - **Cost-Sensitive Learning:** Modify the learning algorithm to take misclassification costs into account.\n",
    "- **Data Augmentation:** Creating synthetic data using techniques like GANs (Generative Adversarial Networks) for image data.\n",
    "\n",
    "#### 1.5 What are overfitting and underfitting? How can you prevent them?\n",
    "\n",
    "**Answer:**\n",
    "- **Overfitting:** The model learns noise instead of patterns, resulting in high training accuracy but low test accuracy. **Prevention:**\n",
    "  - **Regularization:** Techniques like L1 (Lasso) and L2 (Ridge) regularization add a penalty to the loss function to prevent overfitting.\n",
    "  - **Dropout:** Randomly dropping neurons during training to prevent co-adaptation.\n",
    "  - **Pruning:** Removing parts of the model that contribute little to the output.\n",
    "  - **More Data:** Increasing the size of the training dataset.\n",
    "- **Underfitting:** The model is too simple and fails to learn patterns, resulting in low accuracy overall. **Prevention:**\n",
    "  - **More Features:** Adding relevant features to the model.\n",
    "  - **Complex Models:** Using more complex models that can capture the underlying patterns.\n",
    "  - **Hyperparameter Tuning:** Adjusting hyperparameters to improve model performance.\n",
    "\n",
    "#### 1.6 Explain different types of feature scaling techniques.\n",
    "\n",
    "**Answer:**\n",
    "- **Normalization (Min-Max Scaling):** Rescales values to a range of [0, 1]. $$X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}$$\n",
    "- **Standardization (Z-score Normalization):** Centers data around mean 0 and variance 1. $$X' = \\frac{X - \\mu}{\\sigma}$$\n",
    "- **Robust Scaling:** Uses median and interquartile range (IQR) for scaling, making it robust to outliers. $$X' = \\frac{X - \\text{median}}{\\text{IQR}}$$\n",
    "\n",
    "#### 1.7 What are the assumptions of linear regression?\n",
    "\n",
    "**Answer:**\n",
    "1. **Linearity:** The relationship between the dependent and independent variables is linear.\n",
    "2. **Independence:** The residuals (errors) are independent.\n",
    "3. **Homoscedasticity:** The variance of the residuals is constant across all levels of the independent variables.\n",
    "4. **Normality:** The residuals should be normally distributed.\n",
    "5. **No Multicollinearity:** The independent variables should not be highly correlated with each other.\n",
    "\n",
    "\n",
    "#### 1.7.1.  Working of Logistic Regression\n",
    "\n",
    "**Logistic Regression** is used for binary classification, meaning it predicts one of two possible outcomes. This approach allows logistic regression to handle binary classification tasks effectively by converting linear combinations of input features into probabilities. \n",
    "\n",
    "**Sigmoid Function:**\n",
    "- The sigmoid function, denoted as $$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$, is used to map any real-valued number into a value between 0 and 1.\n",
    "- This function outputs probabilities, which helps in determining the likelihood of a particular class.\n",
    "\n",
    "**Decision Rule:**\n",
    "- If the probability \\(P(Y=1)\\) is greater than a certain threshold (commonly 0.5), the model predicts 1 (positive class).\n",
    "- Otherwise, it predicts 0 (negative class).\n",
    "\n",
    "#### 1.8 Explain PCA (Principal Component Analysis) and its use.\n",
    "\n",
    "**Answer:**\n",
    "- **PCA:** A dimensionality reduction technique that transforms correlated variables into a smaller set of uncorrelated variables (principal components).\n",
    "- **Steps:**\n",
    "  1. Standardize the data.\n",
    "  2. Compute the covariance matrix.\n",
    "  3. Compute the eigenvalues and eigenvectors of the covariance matrix.\n",
    "  4. Select the top k principal components.\n",
    "  5. Project the data onto the new subspace.\n",
    "- **Use Cases:** Reducing dimensionality in machine learning models, visualization, noise reduction.\n",
    "\n",
    "#### 1.9 How do decision trees work? How can you prevent overfitting in them?\n",
    "\n",
    "**Answer:**\n",
    "- **Decision Trees:** Recursively split the data based on features that maximize information gain (measured using metrics like entropy or Gini index).\n",
    "- **Overfitting Prevention:**\n",
    "  - **Pruning:** Removing branches that have little importance (pre-pruning and post-pruning).\n",
    "  - **Limiting Tree Depth:** Setting a maximum depth for the tree.\n",
    "  - **Minimum Samples per Leaf:** Setting a minimum number of samples required to split a node.\n",
    "\n",
    "#### 1.10 What is the difference between Bagging and Boosting?\n",
    "\n",
    "**Bagging (Bootstrap Aggregation):**\n",
    "- **Training Process:** Bagging involves training multiple models independently on different bootstrap samples of the data. Bootstrap samples are created by randomly sampling the dataset with replacement, meaning some data points may be repeated in each sample.\n",
    "- **Parallelism:** Since each model is trained independently, they can be trained in parallel, which can significantly speed up the training process.\n",
    "- **Variance Reduction:** Bagging is particularly effective for reducing high variance in models. By averaging the predictions of multiple models, it reduces the overall variance and improves the model's robustness.\n",
    "- **Example:** Random Forest is a popular example of a bagging algorithm. It builds multiple decision trees and averages their predictions to improve accuracy and control overfitting.\n",
    "\n",
    "**Boosting:**\n",
    "- **Training Process:** Boosting involves training models sequentially, where each model attempts to correct the errors made by the previous models. The data is used in a sequence, with each model focusing on the instances that were misclassified by the previous ones.\n",
    "- **Sequential Training:** Unlike bagging, boosting trains models one after another, with each new model being influenced by the performance of the previous models.\n",
    "- **Bias Reduction:** Boosting is effective for reducing high bias in models. By focusing on the errors of previous models, it iteratively improves the model's performance.\n",
    "- **Examples:** AdaBoost, Gradient Boosting, and XGBoost are popular examples of boosting algorithms. They build a series of weak learners (e.g., decision trees) and combine their predictions to create a strong learner.\n",
    "\n",
    "#### 1.11 How does XGBoost work?\n",
    "\n",
    "**XGBoost:** XGBoost (Extreme Gradient Boosting) is an advanced implementation of gradient boosting that builds decision trees sequentially.\n",
    "\n",
    "**Key Features:**\n",
    "- **Regularization:** XGBoost includes L1 (Lasso) and L2 (Ridge) regularization terms in its objective function to prevent overfitting. Regularization helps in controlling the complexity of the model by penalizing large coefficients.\n",
    "- **Handling Missing Values:** XGBoost can automatically handle missing values during training. It learns the best direction to take when encountering a missing value, making it robust to incomplete data.\n",
    "- **Parallel Processing:** XGBoost utilizes parallel processing to speed up the training process. It can build trees in parallel, making it faster than traditional gradient boosting implementations.\n",
    "- **Pruning:** XGBoost uses a technique called \"max depth\" to prevent overfitting. It prunes trees by limiting their maximum depth, ensuring that the model does not become too complex and overfit the training data.\n",
    "\n",
    "#### 1.12 What is the difference between L1 and L2 regularization?\n",
    "\n",
    "**L1 Regularization (Lasso):**\n",
    "- **Penalty Term:** L1 regularization adds the absolute value of the coefficients as a penalty term to the loss function. This encourages sparsity in the model by shrinking some coefficients to exactly zero.\n",
    "  $$\\text{Loss function} = \\text{RSS} + \\lambda \\sum_{j=1}^{p} | \\beta_j |$$\n",
    "  where RSS is the residual sum of squares, \\(\\lambda\\) is the regularization parameter, and \\(\\beta_j\\) are the coefficients.\n",
    "\n",
    "- **Feature Selection:** Because L1 regularization can shrink some coefficients to zero, it effectively performs feature selection by excluding irrelevant features from the model.\n",
    "\n",
    "**L2 Regularization (Ridge):**\n",
    "- **Penalty Term:** L2 regularization adds the squared value of the coefficients as a penalty term to the loss function. This encourages small but non-zero coefficients, leading to a more evenly distributed set of weights.\n",
    "  $$\\text{Loss function} = \\text{RSS} + \\lambda \\sum_{j=1}^{p} \\beta_j^2$$\n",
    "  where RSS is the residual sum of squares, \\(\\lambda\\) is the regularization parameter, and \\(\\beta_j\\) are the coefficients.\n",
    "\n",
    "- **Coefficient Shrinkage:** L2 regularization shrinks the coefficients but does not eliminate them completely. It helps in reducing the impact of multicollinearity and improving the model's generalization.\n",
    "\n",
    "**ElasticNet:** \n",
    "- **Penalty Term:** ElasticNet is a combination of both L1 and L2 regularization. It includes both the absolute and squared values of the coefficients in the penalty term, providing a balance between feature selection and coefficient shrinkage.\n",
    "  $$\\text{Loss function} = \\text{RSS} + \\lambda_1 \\sum_{j=1}^{p} | \\beta_j | + \\lambda_2 \\sum_{j=1}^{p} \\beta_j^2$$\n",
    "  where RSS is the residual sum of squares, \\(\\lambda_1\\) and \\(\\lambda_2\\) are the regularization parameters for L1 and L2 penalties, respectively, and \\(\\beta_j\\) are the coefficients.\n",
    "\n",
    "#### 1.13 What is the curse of dimensionality? How do you handle it?\n",
    "\n",
    "**Curse of Dimensionality:** The curse of dimensionality refers to the phenomenon where the performance of machine learning algorithms degrades as the number of dimensions (features) increases. As the dimensionality increases, the data becomes sparse, and the distance between data points becomes less meaningful, making distance-based algorithms less effective.\n",
    "\n",
    "**Solutions:**\n",
    "- **Dimensionality Reduction:** Techniques like PCA (Principal Component Analysis), t-SNE (t-Distributed Stochastic Neighbor Embedding), and UMAP (Uniform Manifold Approximation and Projection) reduce the number of dimensions while preserving the most important information.\n",
    "- **Feature Selection:** Selecting the most relevant features based on their importance or correlation with the target variable can help reduce the dimensionality and improve the model's performance.\n",
    "- **Regularization:** Adding regularization terms to the loss function can help prevent overfitting by penalizing large coefficients and reducing the model's complexity.\n",
    "\n",
    "#### 1.14 What is the difference between KNN and K-Means?\n",
    "\n",
    "**KNN (K-Nearest Neighbors):**\n",
    "- **Type:** KNN is a supervised learning algorithm used for classification and regression tasks.\n",
    "- **Usage:** It classifies a data point based on the majority class among its k-nearest neighbors. For regression, it predicts the value based on the average of the k-nearest neighbors.\n",
    "- **Mechanism:** KNN calculates the distance (e.g., Euclidean distance) between the data points and assigns the class or value based on the nearest neighbors.\n",
    "\n",
    "**K-Means:**\n",
    "- **Type:** K-Means is an unsupervised clustering algorithm.\n",
    "- **Usage:** It groups similar data points into k clusters based on their features. The algorithm iteratively assigns data points to clusters and updates the cluster centroids until convergence.\n",
    "- **Mechanism:** K-Means minimizes the within-cluster variance by assigning data points to the nearest cluster centroid and recalculating the centroids.\n",
    "\n",
    "#### 1.15 What is Transfer Learning?\n",
    "\n",
    "**Transfer Learning:** Transfer learning is a technique where a pre-trained model on a large dataset is fine-tuned for a different but related task. It leverages the knowledge gained from the pre-trained model to improve performance on the new task.\n",
    "\n",
    "**Examples:**\n",
    "- **Image Classification:** Using a pre-trained model like VGG16, ResNet, or Inception on ImageNet and fine-tuning it for a specific image classification task. The pre-trained model's weights serve as a starting point, and the model is further trained on the new dataset.\n",
    "- **Natural Language Processing:** Using a pre-trained model like BERT, GPT-3, or RoBERTa and fine-tuning it for tasks like sentiment analysis, text classification, or text generation. The pre-trained model's language understanding is transferred to the new task, improving performance with less training data.\n",
    "\n",
    "#### 1.16 What is cross-validation and why is it important?\n",
    "\n",
    "**Answer:**\n",
    "- **Cross-Validation:** A technique used to evaluate the performance of a machine learning model by dividing the data into multiple subsets (folds). The model is trained on some folds and tested on the remaining fold(s). This process is repeated multiple times, and the results are averaged to provide a more robust estimate of model performance.\n",
    "- **Importance:**\n",
    "  - **Reduces Overfitting:** By validating the model on different subsets of data, cross-validation helps ensure that the model generalizes well to unseen data.\n",
    "  - **Model Selection:** Helps in selecting the best model and hyperparameters by comparing performance across different folds.\n",
    "  - **Bias-Variance Tradeoff:** Provides insights into the bias-variance tradeoff by showing how the model performs on different subsets of data.\n",
    "\n",
    "#### 1.17 What is the difference between parametric and non-parametric models?\n",
    "\n",
    "**Answer:**\n",
    "- **Parametric Models:** Assume a specific form for the underlying function and have a fixed number of parameters. **Examples:** Linear regression, logistic regression.\n",
    "  - **Advantages:** Simpler, faster to train, and easier to interpret.\n",
    "  - **Disadvantages:** May not capture complex patterns in the data.\n",
    "- **Non-Parametric Models:** Do not assume a specific form for the underlying function and can have a flexible number of parameters. \n",
    "**Examples:** Decision trees, k-nearest neighbors.\n",
    "  - **Advantages:** Can capture complex patterns and relationships in the data.\n",
    "  - **Disadvantages:** Can be computationally expensive and may require more data to achieve good performance.\n",
    "\n",
    "#### 1.18 What is gradient descent and how does it work?\n",
    "\n",
    "**Answer:**\n",
    "- **Gradient Descent:** An optimization algorithm used to minimize the loss function by iteratively updating the model parameters in the direction of the negative gradient.\n",
    "- **Steps:**\n",
    "  1. Initialize the model parameters randomly.\n",
    "  2. Compute the gradient of the loss function with respect to the parameters.\n",
    "  3. Update the parameters by moving in the direction of the negative gradient, scaled by a learning rate.\n",
    "  4. Repeat steps 2 and 3 until convergence (i.e., the loss function reaches a minimum or stops decreasing).\n",
    "- **Variants:**\n",
    "  - **Batch Gradient Descent:** Uses the entire dataset to compute the gradient.\n",
    "  - **Stochastic Gradient Descent (SGD):** Uses a single data point to compute the gradient.\n",
    "  - **Mini-Batch Gradient Descent:** Uses a small batch of data points to compute the gradient.\n",
    "\n",
    "### Batch Gradient Descent\n",
    "- **Definition:** Batch Gradient Descent computes the gradient of the cost function with respect to the parameters for the entire training dataset. \n",
    "- **Process:** In each iteration, it updates the parameters by taking a step in the direction of the negative gradient of the cost function.\n",
    "- **Formula:** \n",
    "  $$\\theta = \\theta - \\eta \\nabla J(\\theta)$$\n",
    "  where \\(\\theta\\) represents the parameters, \\(\\eta\\) is the learning rate, and \\(\\nabla J(\\theta)\\) is the gradient of the cost function \\(J(\\theta)\\) with respect to \\(\\theta\\).\n",
    "- **Advantages:** \n",
    "  - Converges to the global minimum for convex error surfaces.\n",
    "  - Stable updates as it uses the entire dataset.\n",
    "- **Disadvantages:** \n",
    "  - Can be very slow and computationally expensive for large datasets.\n",
    "  - Requires enough memory to handle the entire dataset.\n",
    "\n",
    "### Stochastic Gradient Descent (SGD)\n",
    "- **Definition:** Stochastic Gradient Descent computes the gradient of the cost function using only a single training example at each iteration.\n",
    "- **Process:** In each iteration, it updates the parameters based on the gradient of the cost function for one randomly chosen data point.\n",
    "- **Formula:** \n",
    "  $$\\theta = \\theta - \\eta \\nabla J(\\theta; x^{(i)}, y^{(i)})$$\n",
    "  where \\(x^{(i)}\\) and \\(y^{(i)}\\) are the \\(i\\)-th training example and its corresponding label.\n",
    "- **Advantages:** \n",
    "  - Faster updates and can handle large datasets.\n",
    "  - Can escape local minima due to its noisy updates.\n",
    "- **Disadvantages:** \n",
    "  - Updates can be noisy, leading to fluctuations in the cost function.\n",
    "  - May not converge to the exact minimum but rather oscillate around it.\n",
    "\n",
    "### Mini-Batch Gradient Descent\n",
    "- **Definition:** Mini-Batch Gradient Descent is a compromise between Batch Gradient Descent and Stochastic Gradient Descent. It computes the gradient using a small batch of training examples.\n",
    "- **Process:** In each iteration, it updates the parameters based on the gradient of the cost function for a mini-batch of data points.\n",
    "- **Formula:** \n",
    "  $$\\theta = \\theta - \\eta \\nabla J(\\theta; X^{(i:i+n)}, Y^{(i:i+n)})$$\n",
    "  where \\(X^{(i:i+n)}\\) and \\(Y^{(i:i+n)}\\) are the mini-batch of training examples and their corresponding labels.\n",
    "- **Advantages:** \n",
    "  - Faster and more efficient than Batch Gradient Descent.\n",
    "  - Reduces the variance of the parameter updates, leading to more stable convergence compared to SGD.\n",
    "- **Disadvantages:** \n",
    "  - Still requires tuning of the mini-batch size.\n",
    "  - May not fully utilize the computational resources if the mini-batch size is too small.\n",
    "\n",
    "#### 1.19 What is the ROC curve and AUC, and how are they used?\n",
    "\n",
    "**Answer:**\n",
    "- **ROC Curve (Receiver Operating Characteristic Curve):** A graphical representation of the true positive rate (recall) versus the false positive rate at various threshold settings. It shows the tradeoff between sensitivity and specificity.\n",
    "- **AUC (Area Under the Curve):** A single scalar value that summarizes the performance of a classifier by measuring the area under the ROC curve. A higher AUC indicates better model performance.\n",
    "- **Usage:**\n",
    "  - **Model Evaluation:** The ROC curve and AUC are used to evaluate the performance of binary classifiers, especially when dealing with imbalanced datasets.\n",
    "  - **Threshold Selection:** Helps in selecting the optimal threshold for classification by visualizing the tradeoff between true positives and false positives.\n",
    "\n",
    "#### 1.20 What is the difference between bagging and boosting?\n",
    "\n",
    "**Answer:**\n",
    "- **Bagging (Bootstrap Aggregating):**\n",
    "  - **Process:** Multiple models are trained independently on different bootstrap samples (random subsets with replacement) of the data. The final prediction is made by averaging the predictions (for regression) or taking a majority vote (for classification).\n",
    "  - **Example:** Random Forest.\n",
    "  - **Advantages:** Reduces variance and helps prevent overfitting.\n",
    "- **Boosting:**\n",
    "  - **Process:** Models are trained sequentially, with each model correcting the errors of the previous one. The final prediction is made by combining the predictions of all models, often with a weighted sum.\n",
    "  - **Example:** AdaBoost, Gradient Boosting, XGBoost.\n",
    "  - **Advantages:** Reduces bias and can achieve higher accuracy by focusing on hard-to-predict instances.\n",
    "\n",
    "\n",
    "\n",
    "| **Feature**         | **Bagging (Bootstrap Aggregating)** | **Boosting**                          |\n",
    "|---------------------|-------------------------------------|---------------------------------------|\n",
    "| **Goal**            | Reduce variance (increase stability) | Reduce bias (increase accuracy)       |\n",
    "| **Training Approach** | Trains models in parallel           | Trains models sequentially            |\n",
    "| **Data Usage**      | Uses random bootstrap samples for each model | Uses the entire dataset but reweights samples |\n",
    "| **Weak Learners**   | Strong models (e.g., deep trees)     | Weak models (e.g., shallow trees, decision stumps) |\n",
    "| **Final Prediction** | Average (Regression) / Majority Voting (Classification) | Weighted sum of all weak learners     |\n",
    "| **Example Algorithms** | Random Forest, Bagging Classifier   | AdaBoost, Gradient Boosting, XGBoost  |\n",
    "\n",
    "\n",
    "\n",
    "#### 1.21 What is the difference between a generative and a discriminative model?\n",
    "\n",
    "**Answer:**\n",
    "- **Generative Models:** Learn the joint probability distribution of the input features and the output labels. They can generate new data points by sampling from this distribution. **Examples:** Naive Bayes, Gaussian Mixture Models.\n",
    "  - **Advantages:** Can be used for data generation and can handle missing data.\n",
    "  - **Disadvantages:** Often more complex and computationally expensive.\n",
    "- **Discriminative Models:** Learn the conditional probability distribution of the output labels given the input features. They focus on the decision boundary between classes. **Examples:** Logistic Regression, Support Vector Machines (SVM).\n",
    "  - **Advantages:** Often simpler and more efficient for classification tasks.\n",
    "  - **Disadvantages:** Cannot generate new data points.\n",
    "\n",
    "#### 1.22 What is the difference between feature selection and feature extraction?\n",
    "\n",
    "**Answer:**\n",
    "- **Feature Selection:** The process of selecting a subset of relevant features from the original set of features. It aims to improve model performance by reducing overfitting and computational complexity. **Techniques:** Filter methods (e.g., correlation), wrapper methods (e.g., recursive feature elimination), embedded methods (e.g., Lasso).\n",
    "- **Feature Extraction:** The process of transforming the original features into a new set of features, often with reduced dimensionality. It aims to capture the most important information from the original features. **Techniques:** PCA (Principal Component Analysis), LDA (Linear Discriminant Analysis), t-SNE (t-Distributed Stochastic Neighbor Embedding).\n",
    "\n",
    "#### 1.23 What is the difference between a confusion matrix and a classification report?\n",
    "\n",
    "**Answer:**\n",
    "- **Confusion Matrix:** A table that summarizes the performance of a classification model by showing the counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). It provides a detailed breakdown of the model's performance for each class.\n",
    "- **Classification Report:** A summary of the key performance metrics for a classification model, including precision, recall, F1-score, and support (the number of true instances for each class). It provides a more comprehensive overview of the model's performance.\n",
    "\n",
    "#### 1.24 What is the difference between hard and soft voting in ensemble methods?\n",
    "\n",
    "**Answer:**\n",
    "- **Hard Voting:** Involves taking the majority vote from the predictions of multiple models. The final prediction is the class that receives the most votes.\n",
    "- **Soft Voting:** Involves averaging the predicted probabilities from multiple models and selecting the class with the highest average probability as the final prediction. Soft voting often provides better performance as it takes into account the confidence of each model's prediction.\n",
    "\n",
    "#### 1.25 What is the difference between a hyperparameter and a parameter in machine learning?\n",
    "\n",
    "**Answer:**\n",
    "- **Parameter:** A variable that is learned by the model during training. **Examples:** Weights in a neural network, coefficients in linear regression.\n",
    "- **Hyperparameter:** A variable that is set before training and controls the learning process. **Examples:** Learning rate, number of hidden layers in a neural network, regularization strength. Hyperparameters are often tuned using techniques like grid search or random search."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
